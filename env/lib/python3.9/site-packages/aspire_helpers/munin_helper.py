import copy
import json
import logging
import os
import re
import time
from functools import wraps
from logging import info, raiseExceptions
from typing import Dict, List
from uuid import uuid4

import requests
import yaml
from requests import Response

from aspire_helpers.constants import (
    LOGGING_FORMAT,
    PII_TYPES,
    EnvVars,
    get_common_var,
    read_yaml,
)
from aspire_helpers.deployment_functions import (
    execute,
    execute_git_diff,
    invoke_snowflake_lambda,
    read_file,
)
from aspire_helpers.helper_functions import write_file
from aspire_helpers.secrets_helper import AWSSecretManager
from aspire_helpers.sf_connector import call_snowflake

logging.basicConfig(format=LOGGING_FORMAT)
logging.getLogger().setLevel(logging.INFO)

config = read_yaml("aspire_helpers_config.yml")

DDL_DIR = get_common_var(EnvVars.DDL_DIR)

database = os.environ["database"]  # GENERAL CONFIG
munin_repo_name = "aspire-munin-schema-registry"
manual_filelist_name = "manual_filenames_for_munin_helper.txt"
logger = logging.getLogger(__name__)
secret_manager = AWSSecretManager(logger)
pipeline_secrets = secret_manager.get_secret(
    config["GITHUB_SERVICE_USER_SSM_SECRET_NAME"]
)  # TEAM SPECIFIC
SERVICE_USER_1_GITHUB_TOKEN = pipeline_secrets[
    "GITHUB_SERVICE_USER_KEY_1"
]  # TEAM SPECIFIC
SERVICE_USER_2_GITHUB_TOKEN = pipeline_secrets[
    "GITHUB_SERVICE_USER_KEY_2"
]  # TEAM SPECIFIC
service_user_auth_path = f"x-access-token:{SERVICE_USER_1_GITHUB_TOKEN}@"
repo_url_base = f"https://{service_user_auth_path}github.com/sainsburys-tech/"
service_user_1_name = config["GITHUB_SERVICE_USER_CONFIG_1"]["NAME"]  # TEAM SPECIFIC
service_user_1_email = config["GITHUB_SERVICE_USER_CONFIG_1"]["EMAIL"]  # TEAM SPECIFIC
service_user_2_name = config["GITHUB_SERVICE_USER_CONFIG_2"]["NAME"]  # TEAM SPECIFIC
service_user_2_email = config["GITHUB_SERVICE_USER_CONFIG_2"]["EMAIL"]  # TEAM SPECIFIC
owner: str = "sainsburys-tech"
github_repo_base_url = f"https://api.github.com/repos/{owner}/{munin_repo_name}"
check_wait_timeout = 1000

# This variable allows the location of the repo to be altered for test
# runs (using mocks) so that the repo can be cloned without interfering
# with the local clones used by each developer
local_name_of_munin_repo = munin_repo_name


def generate_github_api_headers(token: str) -> dict:
    """
    Templated headers for github api calls
    """
    return {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/vnd.github+json",
    }


def get_columns_from_snowflake(table_name: str) -> list:
    """
    Use show columns function in snowflake to get the list of columns for an object
    """
    config = {
        "sql": [
            f"USE ROLE RL_{database}_OBJECT_OWNER;",
            f"USE DATABASE ADW_{database};",
            f"SHOW COLUMNS ON {table_name};",
        ]
    }
    columns_query = [f"SHOW COLUMNS ON {table_name};"]

    column_info = call_snowflake(
        sql_queries=columns_query, suppress_success_statements=True
    )

    columns = column_info[2].tolist()
    logging.info(columns)
    return columns


def get_columns_from_ddl(ddl: str) -> list:
    """
    Parses ddl string and pulls out the column names that are found.
    """
    ddl = " ".join(ddl.upper().split())

    to_remove = [
        "CREATE ",
        " TABLE ",
        " VIEW ",
        " OR ",
        " REPLACE ",
        " COPY ",
        " GRANTS ",
    ]
    for item in to_remove:
        ddl = ddl.replace(item, " ")

    columns = []
    if " SELECT " in ddl and " FROM " in ddl:
        ddl_list: List[str] = ddl.split(" SELECT ")[1].split(" FROM ")[0].split(",")
        for item in ddl_list:
            if "AS" in item:
                columns.append(item.split(" AS ")[1].strip())
            else:
                columns.append(item.strip())
    else:
        # Regex to remove brackets in type definitions e.g NUMBER(18,0)
        # before splitting by brackets around column definition in ddl
        ddl = re.sub(r"\(\d*,?\d*\)", " ", ddl)
        split_ddl: List[str] = ddl.split("(")[1].split(")")[0].split(",")

        for item in split_ddl:
            columns.append(item.strip().split(" ")[0])

    return columns


def get_data_classifications(file_path: str) -> dict:
    """
    Generates the table and column names with associated classifications
    from given configuration file
    """
    file = read_yaml(file_path)
    if file == None:
        logging.info("Classifications.yaml is empty")
        return None

    result = {}

    for key, value in file.items():
        schema, table, column = key.split(".")
        schema_table = f"{schema}.{table}"

        result.setdefault(schema_table, {})

        result[schema_table][column] = value
        if value not in PII_TYPES:
            # Fail loudly PII_TYPE not correctly worded
            logging.exception(
                f"ðŸ’¥ {value} called is not correctly formatted/ existing - exiting."
            )
            raise NameError("PII Type incorrect")

    return result


def generate_yaml_from_column_names(
    column_names: list, classifications: dict, table_name: str
) -> str:
    """
    Generates the yaml format that is expected by the munin schema registry, based on the
    column names that are provided as input, and the classfications for each column.
    """
    yaml = "COLUMNS:\n"
    column_block = "- CLASSIFICATION: {class_type}\n  COLUMN_NAME: {col_name}\n"

    for col in column_names:
        class_type = classifications.get(table_name, {}).get(col, "COMMERCIAL")
        yaml += column_block.format(class_type=class_type, col_name=col)
    return yaml


def restore_git_settings(func):
    """
    Decorator that stores the users local git settings and then reapplies them once the function is complete.
    This enables service users to be used locally without messing up local development settings.
    """

    @wraps(func)
    def wrapper(*args, **kwargs):
        # Do something before the function.
        user_name = ""
        user_email = ""

        try:
            user_name = execute("git config user.name")[0]
        except IndexError:
            logging.info("No prior git user name set")

        try:
            user_email = execute("git config user.email")[0]
        except IndexError:
            logging.info("No prior git user name set")

        logging.info(f"Storing git user name {user_name} and email {user_email}")
        try:
            func(*args, **kwargs)
            set_git_user(user_name, user_email)

        except:
            # Do something after the function.
            set_git_user(user_name, user_email)
            raise

        set_git_user(user_name, user_email)

    return wrapper


def set_git_user(user_name: str, email: str) -> None:
    """
    Sets github user based on email and user name, so that service users can be used as
    part of this code.
    """

    execute(f"git config user.name {user_name} --replace-all")
    execute(f"git config user.email {email} --replace-all")


@restore_git_settings
def raise_and_merge_pull_request() -> None:
    """
    Raise a pull request on the munin schema registry and automatically
    close it (if the checks succeed). Will auto detect changes based on changes to ddl in
    the data product repo, and push these changes to the munin schema registry.
    """
    create_munin_pr()
    merge_munin_pr()


@restore_git_settings
def create_munin_pr() -> None:
    set_git_user(service_user_1_name, service_user_1_email)
    file_paths = get_filepaths_for_munin()

    if len(file_paths) == 0:
        logging.info("MUNIN HELPER: No Munin changes to deploy, stopping")
        return

    logging.info("MUNIN HELPER: Changes to deploy")
    logging.info(file_paths)

    clone_munin_repo()
    munin_branch_name = get_munin_branch_name().replace('"', "")

    checkout_munin_branch_cmds = f"""
        cd ../{munin_repo_name};
        git checkout main;
        git pull;
        git checkout -b {munin_branch_name};
        git checkout {munin_branch_name};
    """
    out = execute(checkout_munin_branch_cmds, multi_statement=True)
    logging.info(out)
    classifications = get_data_classifications("data_classifications.yaml")
    for path in file_paths:
        object_type = get_object_type_from_path(path)
        object_name = path.split("/")[-1].replace(".sql", "")
        columns = get_columns_from_snowflake(object_name)
        yaml = generate_yaml_from_column_names(columns, classifications, object_name)
        object_name_as_path = object_name.replace(".", f"/{object_type}#")
        logging.info(yaml)
        write_file(
            yaml,
            f"../{munin_repo_name}/SAINSBURYS/ADW_{database}/{object_name_as_path}.yaml",
        )

    commit_and_push_cmds = f"""
        cd ../{munin_repo_name};
        git config user.name {service_user_1_name} --replace-all
        git config user.email {service_user_1_email} --replace-all
        git add .;
        git commit -m \'munin helper: adding classifications\';
        git push -u origin {munin_branch_name} -f;
    """
    execute(commit_and_push_cmds, multi_statement=True)

    pr_number = raise_pull_request_if_not_raised(head_branch=munin_branch_name)
    logging.info(f"Pull Request number: {pr_number}")


@restore_git_settings
def merge_munin_pr() -> None:
    set_git_user(service_user_2_name, service_user_2_email)
    munin_branch_name = get_munin_branch_name()
    pr_number = raise_pull_request_if_not_raised(head_branch=munin_branch_name)

    if pr_number is not None:
        approve_pull_request(pr_number)
        wait_for_checks_to_complete(munin_branch_name)
        merge_pull_request(pr_number)


def get_object_name_from_ddl(ddl: str) -> str:
    """
    Get the name of an object in DDL string
    """
    if " TABLE " in ddl:
        split_ddl = ddl.split(" TABLE ")
    elif " VIEW " in ddl:
        split_ddl = ddl.split(" VIEW ")

    return split_ddl[1].split(" ")[0]


def get_object_type_from_path(path: str) -> str:
    """
    Determine the type of object in a DDL string
    """
    path = path.upper()
    if "TABLE" in path and "VIEW" in path:
        raise Exception(
            """
            File path has both table and view it should have one not both,
            this is ambigious, please correct this before proceeding
            """
        )
    elif "TABLE" in path:
        return "TABLE"
    elif "VIEW" in path:
        return "VIEW"
    else:
        raise Exception(
            """
            Cannot Find Object Type, please check the file path
            """
        )


def get_munin_branch_name():
    """
    Logic for deciding what the branch should be named, can be overridden by setting
    an environment variable, otherwise will auto generate the name based of the
    commit id.
    """
    try:
        if database in ("PROD", "PREPROD", "DEV") and os.getenv("MUNIN_BRANCH") == None:
            os.environ["MUNIN_BRANCH"] = generate_munin_branch_name()
        munin_branch_name = os.environ["MUNIN_BRANCH"]
        logging.info(f"Using munin branch name: {munin_branch_name} from env var")
        return munin_branch_name.replace('"', "")
    except:
        raise Exception(
            """
            You need to set a branch name to use for munin.
            Try setting MUNIN_BRANCH={ticket-number}-{environment} in your terminal
            """
        )


def generate_munin_branch_name() -> str:
    """
    Gets commit id and uses this to create a unique branch name
    on the munin repo. This also allows for reuse of the same branch if you are
    on the same commit. Example branch name would be:
    Munin-Helper-DEV-0d9071bd0d661f2e83bdc0216578c6fc739b723a
    Using the commit id also allows you to track back to exactly where
    the munin PR was generated from.
    """
    commit_id = execute('git log --format="%H" -n 1')[0]
    return f"Munin-Helper-{database}-{commit_id}"


def get_filepaths_for_munin(manual: bool = False) -> List[str]:
    if manual:
        try:
            filepaths = read_file(manual_filelist_name).splitlines()
            filepaths = [x.strip() for x in filepaths]
        except:
            raise Exception(f"You need to create a file named {manual_filelist_name}")
    else:
        filepaths = execute_git_diff(DDL_DIR + "Tables") + execute_git_diff(
            DDL_DIR + "Views"
        )
    return filepaths


def clone_munin_repo() -> bool:
    """
    This function clones the munin repo only if the repo is not
    already found locally. Returns True if the repo did not already
    exist, and needed to be cloned.
    """
    file_exists = os.path.exists(f"../{munin_repo_name}")

    if file_exists:
        logging.info(f"Found munin repo locally: {munin_repo_name}")
        return False
    else:
        logging.info(
            f"No local clone of {munin_repo_name} found, cloning to local now..."
        )
        execute(f"git clone {repo_url_base}/{munin_repo_name}.git ../{munin_repo_name}")
        return True


def request_exception_handler(res):
    """
    Fail loudly if the response from the server is not ok.
    """
    if res.status_code not in (200, 201):
        raise Exception(res.text)


def raise_pull_request_if_not_raised(head_branch: str, base_branch: str = "main"):
    """
    Only raise PR if not already raised
    """
    pr_number = check_for_existing_pull_request(head_branch=head_branch)
    logging.info("1----------->>>>>>>>>>")
    logging.info(execute("git config user.name"))
    logging.info("2----------->>>>>>>>>>")
    if pr_number is None and check_for_diff():
        return raise_pull_request(head_branch=head_branch)
    else:
        return pr_number


def check_for_diff() -> bool:
    """
    Check if there is anything to raise a PR with
    """
    cmd = f"""
        cd ../{munin_repo_name};
        git diff --diff-filter=d origin/main --name-only;
    """
    diff_files = execute(cmd, multi_statement=True)
    if len(diff_files) > 0:
        return True
    else:
        return False


def raise_pull_request(head_branch: str, base_branch: str = "main"):
    """
    Raise a PR on using the github api
    """
    url = f"{github_repo_base_url}/pulls"

    payload = {
        "title": head_branch,
        "body": "Auto Generated from DDL by Munin Helper",
        "head": head_branch,
        "base": base_branch,
    }

    res = requests.post(
        url,
        headers=generate_github_api_headers(SERVICE_USER_1_GITHUB_TOKEN),
        data=json.dumps(payload),
    )

    request_exception_handler(res)

    return res.json()["number"]


def check_for_existing_pull_request(head_branch: str, base_branch: str = "main") -> str:
    """
    Check that PR has not already be raised
    """
    url = f"{github_repo_base_url}/pulls"

    payload = {"state": "open", "head": head_branch}

    res = requests.get(
        url,
        headers=generate_github_api_headers(SERVICE_USER_1_GITHUB_TOKEN),
        data=json.dumps(payload),
    )

    request_exception_handler(res)

    return check_if_pr_found(res, head_branch)


def check_if_pr_found(res, branch_name):
    """
    Look for prs in the list of PRs in the github api based on the branch name.
    """
    results_found = len(res.json()) > 0

    if results_found:
        is_branch_name_found = branch_name in res.json()[0]["head"]["label"]
        includes_pr_number = "number" in res.json()[0]

        if is_branch_name_found and includes_pr_number:
            return res.json()[0]["number"]

    return None


def approve_pull_request(pr_number) -> None:
    """
    See here for github docs
    https://docs.github.com/en/rest/pulls/reviews
    """

    url = f"{github_repo_base_url}/pulls/{pr_number}/reviews"
    payload = {"body": "Auto Approved by Munin Helper", "event": "APPROVE"}

    res = requests.post(
        url,
        headers=generate_github_api_headers(SERVICE_USER_2_GITHUB_TOKEN),
        data=json.dumps(payload),
    )

    logging.info("MUNIN HELPER: Approving PR")
    return res.json()["id"]


def wait_for_checks_to_complete(branch: str) -> bool:
    """
    See here for github docs
    https://docs.github.com/en/rest/checks/runs#get-a-check-run
    """
    url = f"{github_repo_base_url}/commits/{branch}/check-runs"

    checks_completed = False
    wait_time = 10

    cumulative_wait = 0
    while not checks_completed:
        res = requests.get(
            url, headers=generate_github_api_headers(SERVICE_USER_2_GITHUB_TOKEN)
        )

        request_exception_handler(res)

        if res.json()["total_count"] > 0:
            if checks_are_completed(res.json()["check_runs"]):
                return True

        if cumulative_wait >= check_wait_timeout:
            break

        time.sleep(10)
        cumulative_wait += wait_time
        logging.info(
            f"MUNIN HELPER: Waiting for Checks to Complete, checking again in {wait_time} seconds"
        )

    return False


def checks_are_completed(checks: list) -> bool:
    """
    Provided a list of checks from the github pr api, check that all of these
    checks have passed.
    """
    for check in checks:
        if check["status"] in ("queued", "in_progress"):
            return False
    return True


def merge_pull_request(pr_number: str) -> None:
    """
    See here for github docs
    https://docs.github.com/en/rest/pulls/pulls#merge-a-pull-request
    """

    url = f"{github_repo_base_url}/pulls/{pr_number}/merge"

    payload = {"merge_method": "squash"}

    res = requests.put(
        url,
        headers=generate_github_api_headers(SERVICE_USER_2_GITHUB_TOKEN),
        data=json.dumps(payload),
    )

    logging.info(f"MUNIN HELPER: Merging PR")
    request_exception_handler(res)

    assert res.status_code == 200
