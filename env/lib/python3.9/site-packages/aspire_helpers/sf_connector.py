import json
import logging
import os
import platform
from datetime import date, datetime, time
from decimal import Decimal
from typing import Dict

import boto3
import botocore
import numpy as np
import pandas as pd
import snowflake.connector
import yaml
from botocore.exceptions import ClientError, ProfileNotFound
from tabulate import tabulate

from aspire_helpers.constants import LOGGING_FORMAT, EnvVars, get_common_var
from aspire_helpers.helper_functions import (
    build_lambda_payload,
    build_snowflake_query,
    read_sql,
)
from aspire_helpers.lambda_functions import invoke_snowflake_lambda
from aspire_helpers.secrets_helper import AWSSecretManager

logging.basicConfig(format=LOGGING_FORMAT)
logging.getLogger().setLevel(logging.INFO)
logger = logging.getLogger(__name__)

pd.set_option("display.max_columns", None)
pd.set_option("display.width", 200)
secret_manager = AWSSecretManager(logger)


class DictCursorEncoder(json.JSONEncoder):
    def default(self, o):
        if isinstance(o, datetime):
            return o.strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]
        elif isinstance(o, date):
            return o.strftime("%Y-%m-%d")
        elif isinstance(o, time):
            return o.strftime("%H:%M")
        elif isinstance(o, Decimal):
            return float(o)


def _default_connection_param():
    """
    Generate the correct Snowflake account name based on the os being used.
    """
    account = "sainsburys.eu-west-1"

    if platform.system() != "Darwin":
        account = f"{account}.privatelink"

    return {
        "account": account,
        "schema": "ADW_STAGE",
    }


def set_proxy_settings(func) -> None:
    """
    Setting the proxy settings so that connection to snowflake can be made. Generally we only want
    the proxy settings enabled when trying to connect to a web resource (website) that is behind
    the vpn, so for example, we dont want to connect to aws through the proxy otherwise we get
    strange behaviour!
    """

    def wrapper_func(*args, **kwargs):
        if platform.system() == "Darwin":
            # Do something before the function.
            os.environ["HTTP_PROXY"] = "http://a-proxy-p.bc.jsplc.net:8080"
            os.environ["HTTPS_PROXY"] = "http://a-proxy-p.bc.jsplc.net:8080"
            result = func(*args, **kwargs)
            # Do something after the function.
            del os.environ["HTTP_PROXY"]
            del os.environ["HTTPS_PROXY"]
        else:
            result = func(*args, **kwargs)

        return result

    return wrapper_func


def get_credentials(service_user=False):
    """
    Retrive Snowflake credentials to use with the Snowflake Connector.
    """
    defaults = _default_connection_param()
    if service_user:
        config = parse_sf_config(service_user=True)
    else:
        config = parse_sf_config()
    logging.info(f"{config['USER']}")
    return {
        "user": config["USER"],
        "password": config["PASSWORD"],
        "account": defaults["account"],
    }


def parse_sf_config(service_user=False):
    """
    Parse the sf_config.yml file within the target repo to retrieve either service user
    or engineer configs. This should include USER, WHS and ETL_ROLE. In the case of Service User
    this will also include USER_SECRET_KEY with which the PASSWORD will be retrieved from AWS SecretsManager.
    When using an Engineer's config, USER and PASSWORD will be retrieved from env variables.
    """
    database = get_common_var(EnvVars.DATABASE)
    with open("aspire_helpers_config.yml", "r") as sf_config:
        config = yaml.load(sf_config, Loader=yaml.FullLoader)
        if service_user:
            sf_config = config[f"SERVICE_USER_{database}"]
            password = secret_manager.get_secret(sf_config["USER_SECRET_KEY"])
            sf_config["PASSWORD"] = password
            return sf_config
        else:
            sf_config = config[f"ENGINEER_{database}"]
            user = os.environ["sf_user"]
            password = os.environ["sf_password"]
            sf_config.update(USER=user, PASSWORD=password)
            return sf_config


def parse_results(cursor):
    """
    Parse the Snowflake query results retrieved by the cursor.
    """
    results = []

    for item in cursor:
        logging.info(f"Original item: {item}")
        json_string = (
            json.dumps(item, cls=DictCursorEncoder)
            .replace("\\n", "")
            .replace("\\r", "")
        )
        logging.info(f"Dumped item: {json_string}")
        results.append(json_string)
    return results


def parse_pandas_results(cursor):  # pragma: no cover
    """
    Parse the Snowflake query results retrieved by the cursor in a Pandas Dataframe format.
    """
    return cursor.fetch_pandas_all()


@set_proxy_settings
def execute_multi_statements(creds, statements):
    """
    Connect to Snowflake using Snowflake Connector using the credentials supplied.
    Execute all statements, parse the results and return everything.
    """
    results = []
    with snowflake.connector.connect(**creds) as ctx:
        with ctx.cursor() as cursor:
            cursor.execute("begin")
            try:
                for statement in statements:
                    cursor.execute(statement)
                    if (
                        "SELECT" in statement.upper()
                        and "CREATE " not in statement.upper()
                    ):
                        results.append(parse_pandas_results(cursor))
                        logging.info(
                            f"\n query: \n {statement.upper()} \n\n result from snowflake: \n {tabulate(cursor, headers='keys', tablefmt='psql')} \n"
                        )
                    else:
                        results.append(parse_results(cursor))
                        logging.info(f"results:{results}")

                cursor.execute("commit")
            except Exception as e:
                cursor.execute("rollback")
                results.append(str(e))
                return results
            cursor.close()
    logging.info(results)
    return results


def call_snowflake(
    route: str = None,
    sql_file_path: str = None,
    sql_queries: list[str] = None,
    replace: dict = {},
    service_user: bool = False,
    suppress_success_statements: bool = False,
) -> pd.DataFrame:
    """
    This function can be used to run a snowflake query either locally via a snowflake connector using the vpn
    OR via an aws lambda. Route, either "local" or "aws" should be stated as an input along with the file path to the
    associating SQL statement(s), or a single string containing the sql query. If any values are to be replaced, they
    will need to be stated in the 'replace' dictionary input. call_snowflake() is set as a default to use the ENGINEER
    user credentials set in your sf_config and env variables. If the service_user is required, this will need to be set
    to True as an input.

    Args:
        route str: Specifies which route you would like the query to be run, `"local"` or `"aws"`. The difference between these two routes is explained in more detail in [confluence](https://sainsburys-confluence.valiantys.net/x/iWqmCg).
        sql_file_path str: File path to a sql file of sql you want to be run on snowflake e.g. `sql_file_path="tests/test_sql_file_path.sql"`. You can only use sql_file_path or sql_queries not both.
        sql_queries list[str]: Specify a list of queries to be run on snowflake. You can only use sql_file_path or sql_queries not both.
        replace dict: Dictionary of any values you want to replace in the provided SQL. E.g. `replace={<<TRANSACTION_ID>>:str(uuid4())}` to replace every instance of <<TRANSACTION_ID>> with a dummy TransactionID when inserting dummy data for testing.
        service_user bool: Set to default `False`. If set to `True`, the service user account described in the `aspire_helpers_config.yml` will be used to log into snowflake instead of the engineers personal account. `service_user=True` must be set when using the `"aws"` route for now as the service user is used by the aws lambda.,
        suppress_success_statements bool: If true it will not return results from queries that do not return data, in order to avoid cluttered output.

    Returns:
        type: Returns rows from snowflake queries.
    """

    if not route:
        route = os.getenv("ROUTE")
        if not route:
            config_details = parse_sf_config()
            if config_details["ROUTE"] == "AWS":
                service_user = True
                config_details = parse_sf_config(service_user=service_user)
                config_details["ROUTE"] = "AWS"
                route = config_details["ROUTE"]
            if route is None:
                raise Exception(
                    "Route not specified, please set the route via one of the three options: input parameter, enviroment variable, or config file"
                )
    if route.lower() == "aws":
        service_user = True

    if service_user:
        config_details = parse_sf_config(service_user=True)
    else:
        config_details = parse_sf_config()

    logging.info(route)

    sql = []
    if sql_file_path:

        sql = read_sql(query_file_path=sql_file_path)
    elif sql_queries:
        sql += sql_queries

    sql = replace_values(sql, replace)

    if route.lower() == "local":
        if service_user:
            credentials = get_credentials(service_user=True)
        else:
            credentials = get_credentials()

        snowflake_payload = build_snowflake_query(sql, config_details)
        output = execute_multi_statements(credentials, snowflake_payload)
        results = output
        # results = pd.DataFrame(output)

    elif route.lower() == "aws":
        config = build_lambda_payload(query_list=sql, config=config_details)
        output = invoke_snowflake_lambda(config)

        if suppress_success_statements:
            output = remove_success_statements(output)

        results = pd.DataFrame(output)

    logging.info(f"\n Result from snowflake:\n {tabulate(results)}")
    return results


def remove_success_statements(output):
    """
    Removes success message from response from snowflake as this is most often not needed
    """
    cleaned_output = []
    for element in output:
        if "Statement executed successfully." != element[0]:
            cleaned_output.append(element)
    return cleaned_output


def replace_values(sql: list[str], replace: dict) -> list[str]:
    """
    Replace given values in the SQL statements.
    """
    for key, value in replace.items():
        sql = sql.replace(key, "'" + value + "'")
    return sql
